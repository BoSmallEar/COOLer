"""Wrapper for mmdet to get output from RPN and ROI heads."""
from typing import Dict, List, Tuple

import torch
from mmdet.core.bbox import build_sampler, build_assigner, SamplingResult

from ilmot.model.detect import MMTwoStageDetector  # type: ignore
from ilmot.struct import Boxes2D, InputSample, LossesType, ArgsType, ModuleCfg  # type: ignore #pylint: disable=line-too-long
from ilmot.common.bbox.utils import bbox_iou  # type: ignore
from ilmot.model.mm_utils import (
    proposals_to_mmdet,
    get_img_metas,
    proposals_from_mmdet,
    targets_to_mmdet,
    _parse_losses,
)
from .detect_utils import bbox2roi


class ILMOTMMDetector(MMTwoStageDetector):  # type: ignore
    """ILMOT wrapper for MMdet detector."""

    # pylint: disable=too-many-ancestors
    # pylint: disable=abstract-method

    def __init__(
        self,
        *args: ArgsType,
        mm_sampler: ModuleCfg,
        mm_assigner: ModuleCfg,
        **kwargs: ArgsType,
    ):
        """Init."""
        self.mm_sampler = build_sampler(mm_sampler)
        self.mm_assigner = build_assigner(mm_assigner)
        super().__init__(*args, **kwargs)

    def get_rpn_output(
        self,
        features: Dict[str, torch.Tensor],
    ) -> Dict[str, torch.Tensor]:
        """Get rpn raw output for cls and reg given backbone features.

        Args:
            features: Feature pyramid.

        Returns:
            RPN raw output for each pyramid level.

        """
        feat_list = list(features.values())
        cls_scores, bbox_preds = self.rpn_head.mm_dense_head.forward(feat_list)
        rpn_output = dict(cls_scores=cls_scores, bbox_preds=bbox_preds)
        return rpn_output

    def get_roi_output(
        self, features: Dict[str, torch.Tensor], proposals: List[Boxes2D]
    ) -> Dict[str, torch.Tensor]:
        """Get roi raw output for cls and reg given proposals.

        Args:
            features: Feature pyramid.
            proposals: Proposals generated by RPN.

        Returns:
            ROI raw output.

        """
        proposal_list = proposals_to_mmdet(proposals)
        rois = bbox2roi(proposal_list)
        feat_list = list(features.values())
        roi_output = self.roi_head.mm_roi_head._bbox_forward(  # pylint: disable=protected-access
            feat_list, rois
        )
        return roi_output  # type: ignore

    def sample_proposals(
        self,
        inputs: InputSample,
        features: Dict[str, torch.Tensor],
    ) -> List[Boxes2D]:
        """Sample proposals that have the lowest background score.

        Args:
            inputs: Preprocessed input samples.
            features: Feature pyramid.

        Returns:
            Proposals with the lowest background score.

        """
        feat_list = list(features.values())
        img_metas = get_img_metas(inputs.images)

        proposals = self.rpn_head.mm_dense_head.simple_test(
            feat_list, img_metas
        )

        def sample_batch(proposal: torch.Tensor) -> torch.Tensor:
            proposal = proposal[:128]
            perm = torch.randperm(proposal.shape[0])  # type: ignore
            idx = perm[:64]
            return proposal[idx]

        proposals = map(sample_batch, proposals)

        return proposals_from_mmdet(proposals)  # type: ignore

    def sample_proposals_student(
        self,
        inputs: InputSample,
        features: Dict[str, torch.Tensor],
    ) -> List[Boxes2D]:
        """Sample Proposals from student."""
        feat_list = list(features.values())
        img_metas = get_img_metas(inputs.images)
        proposals = self.rpn_head.mm_dense_head.simple_test(
            feat_list, img_metas
        )
        gts = inputs.targets.boxes2d

        def sample_batch(proposal: torch.Tensor, gt: Boxes2D) -> torch.Tensor:
            ious = bbox_iou(Boxes2D(proposal), gt)
            max_iou, _ = torch.max(ious, dim=1)
            mask = max_iou < 0.5
            proposal = proposal[mask]
            proposal = proposal[:128]
            perm = torch.randperm(proposal.shape[0])  # type: ignore
            idx = perm[:64]
            return proposal[idx]

        proposals = map(sample_batch, proposals, gts)
        return proposals_from_mmdet(proposals)

    def process_proposals(
        self,
        true_labels: List[Boxes2D],
        pseudo_labels: List[Boxes2D],
        proposals: List[Boxes2D],
    ) -> Tuple[List[SamplingResult], List[Boxes2D]]:
        """Process proposals."""
        num_images = len(true_labels)
        sample_results = []
        fake_proposals = []
        for i in range(num_images):
            num_real_gts = true_labels[i].class_ids.shape[0]
            gt_boxes = torch.cat(
                [true_labels[i].boxes[:, :4], pseudo_labels[i].boxes[:, :4]],
                dim=0,
            )
            gt_labels = torch.cat(
                [true_labels[i].class_ids, pseudo_labels[i].class_ids],
                dim=0,
            )
            gt_labels = gt_labels.to(torch.long)
            boxes = proposals[i].boxes[:, :4]
            assign_result = self.mm_assigner.assign(
                boxes, gt_boxes, None, gt_labels
            )
            sample_result = self.mm_sampler.sample(
                assign_result, boxes, gt_boxes, gt_labels
            )

            mask = sample_result.pos_assigned_gt_inds < num_real_gts

            fake_proposals.append(
                sample_result.pos_bboxes[torch.logical_not(mask)]
            )

            sample_result.num_gts = num_real_gts
            sample_result.pos_assigned_gt_inds = (
                sample_result.pos_assigned_gt_inds[mask]
            )
            sample_result.pos_bboxes = sample_result.pos_bboxes[mask]
            sample_result.pos_inds = sample_result.pos_inds[mask]
            sample_result.pos_is_gt = sample_result.pos_is_gt[mask]
            sample_result.pos_gt_labels = sample_result.pos_gt_labels[mask]
            sample_result.pos_gt_bboxes = sample_result.pos_gt_bboxes[mask]

            sample_results.append(sample_result)

        fake_proposals = proposals_from_mmdet(fake_proposals)

        return sample_results, fake_proposals

    def sample_proposals_contrast(
        self,
        labels: List[Boxes2D],
        proposals: List[Boxes2D],
        use_bg: bool = True,
    ) -> List[Boxes2D]:
        """Sample proposals used for contrastive learning."""
        num_images = len(labels)
        sampled_proposals: List[Boxes2D] = []
        for i in range(num_images):
            gt_boxes = labels[i].boxes[:, :4]
            gt_labels = labels[i].class_ids
            boxes = proposals[i].boxes[:, :4]
            scores = proposals[i].boxes[:, 4]
            assign_result = self.mm_assigner.assign(
                boxes, gt_boxes, None, gt_labels
            )
            sample_result = self.mm_sampler.sample(
                assign_result, boxes, gt_boxes, gt_labels
            )
            pos_proposals = sample_result.pos_bboxes
            pos_class_ids = sample_result.pos_gt_labels
            neg_proposals = sample_result.neg_bboxes
            neg_scores = scores[sample_result.neg_inds - sample_result.num_gts]
            neg_inds = torch.argsort(neg_scores, descending=True)
            # sample bg proposals with the highest fg score in rpn
            neg_proposals = neg_proposals[neg_inds]
            neg_scores = neg_scores[neg_inds]
            neg_proposals = neg_proposals[neg_scores > 0.7, :]
            if use_bg:
                neg_class_ids = torch.full(
                    [neg_proposals.shape[0]],
                    fill_value=-1,
                    dtype=pos_class_ids.dtype,
                    device=pos_class_ids.device,
                )
                contrast_proposals = torch.cat(
                    [pos_proposals, neg_proposals], dim=0
                )
                contrast_class_ids = torch.cat(
                    [pos_class_ids, neg_class_ids], dim=0
                )
            else:
                contrast_proposals = pos_proposals
                contrast_class_ids = pos_class_ids

            sampled_proposals.append(
                Boxes2D(contrast_proposals, contrast_class_ids)
            )
        return sampled_proposals

    def get_proposals_embeddings(
        self,
        features: Dict[str, torch.Tensor],
        proposals: List[Boxes2D],
    ):
        """Get proposal embeddings."""
        proposal_list = proposals_to_mmdet(proposals)
        feat_list = list(features.values())

        rois = bbox2roi(proposal_list)
        bbox_feats = self.roi_head.mm_roi_head.bbox_roi_extractor(
            feat_list[
                : self.roi_head.mm_roi_head.bbox_roi_extractor.num_inputs
            ],
            rois,
        )
        if self.roi_head.mm_roi_head.with_shared_head:
            bbox_feats = self.roi_head.mm_roi_head.shared_head(bbox_feats)

        x = bbox_feats
        bbox_head = self.roi_head.mm_roi_head.bbox_head
        if bbox_head.num_shared_convs > 0:
            for conv in bbox_head.shared_convs:
                x = conv(x)

        if bbox_head.num_shared_fcs > 0:
            if bbox_head.with_avg_pool:
                x = bbox_head.avg_pool(x)

            x = x.flatten(1)

            for fc in bbox_head.shared_fcs:
                x = bbox_head.relu(fc(x))

        embeddings = x

        return embeddings

    def forward_sample_results(
        self,
        inputs: InputSample,
        features: Dict[str, torch.Tensor],
        sample_results: List[SamplingResult],
    ) -> LossesType:
        """Forward sample results."""
        feat_list = list(features.values())
        img_metas = get_img_metas(inputs.images)
        # fmt: off
        gt_bboxes, gt_labels = targets_to_mmdet(inputs.boxes2d) # pylint: disable=unbalanced-tuple-unpacking
        # fmt: on
        losses = {}
        bbox_results = self.roi_head.mm_roi_head._bbox_forward_train(  # pylint: disable=protected-access
            feat_list,
            sample_results,
            gt_bboxes,
            gt_labels,
            img_metas,
        )
        losses.update(bbox_results["loss_bbox"])
        detect_losses = _parse_losses(losses)

        return detect_losses
